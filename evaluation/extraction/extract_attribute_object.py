import os
import glob
import random
import json
import openai
import time
import json
import numpy as np
import sys
sys.path.append("../")
from gpt_model import llm, set_key
import tqdm
import argparse

def main(args):
    set_key()
    
    path = args.caption_path

    with open(path, "r") as f:
        generated_caps = json.load(f)
        
    messages = [
        {
            "role": "system", 
            "content": "You are a language assistant that helps to extract the ranking from given sentences." 
        },
    ]
    content = """
        Given an image with a caption that is generated by a vision language model. 
        Please act as a linguistic master and extract the total number and colors of all objects as mentioned in the captions.
        Your answer should be a dict of this format: {"total_num_of_objects": "(NUM, OBJECT)", "objects": {"ORDER": "(ATTRIBUTE, OBJECT)"}}. Remember OBJECT should be in singular format.
        
        For clarity, consider these examples:
        
        ### Example 1:
        - Caption: The image shows a set of five colorful modeling clay sticks neatly aligned side by side against a light-colored, almost white background. From left to right, the sequence of colors is as follows:\n\n1. Pink: A vibrant shade of pink, the stick has a slightly flattened side from being pressed or laid down upon a surface, with the other sides retaining a more rounded shape characteristic of new modeling clay sticks.\n2. Red: Next to the pink, a brilliant red stick is placed. Like the pink, it shows signs of slight use, with minor indentations and a softened shape.\n3. Orange: A bright orange stick follows the red one. It seems to be in a similarly used condition as the others, with a mix of flattened and rounded edges.\n4. Yellow: A pure, sunshine yellow stick, again, showing a little bit of wear.\n5. Green: A vivid green stick represents the fifth color. As with its predecessors, it has a slightly squished appearance indicating it has been handled or used.\nIt mirrors the others in terms of the minor signs of use visible on its surface.\n\nThe sticks are placed closely together, creating a rainbow-like gradient from pink to blue. The light is consistent across the photo, which, along with the plain background, draws attention to the bright colors of the clay sticks. From this angle, we cannot see the length of the sticks, but they appear to have a standard length similar to commonly available modeling clay sticks.
        - Result: {"total_num_of_objects": "(5, "clay sticks"), (1, background)", "objects": {"1": "(pink, clay sticks)", "2": "(red, clay sticks)", "3": "(orange, clay sticks)", "4": "(yellow, clay sticks)", "5": "(green, clay sticks)", "6": "(white, background)"}}

        ### Example 2:
        - Caption: On the top shelf, from left to right:\n- A wooden bowl containing two apples. The apples have a yellowish color with some green and brown areas, suggesting they may be golden apples or a similar variety.\n\nOn the bottom shelf, from left to right:\n- The first object is a brown ceramic cup standing upright.\n- The second object is another brown ceramic cup, positioned upside down on top of the first cup, so they form a closed cylinder together.\n- The third object is a stack of two white ceramic cups with a grey band near the bottom.\n- To the right of these cups, there is a stack of five white ceramic bowls.
        - Result: {"total_num_of_objects": "(2, apples), (4, cups), (6, bowls)", "objects": {"1": "(wooden, bowl)", "2": "(yellowish green, apple)", "3": "(yellowish green, apple)", "4": "(brown, cup)", "5": "(brown, cup)", "6": "(white with grey band, cup)", "6": "(white with grey band, cup)", "7": "(white, bowl)", "7": "(white, bowl)", "8": "(white, bowl)", "9": "(white, bowl)", "10": "(white, bowl)"}}
        
        With these examples in mind, please help me extract the relations based on the information in the caption. You should only return a JSON file without any explanations.
        Here is the caption:
        [CAPTION]
    """
    
    outpath = args.output_file_path
    
    for image_id, cap in tqdm.tqdm(list(generated_caps.items())):
        cap_to_gpt = cap["generated_caption"]

        input = content.replace("[CAPTION]", cap_to_gpt) 
        prompt = messages + [{"role": "user", "content": input}]
        llm_output = llm(prompt)
        current_output = {
            "image_id": image_id,
            "response": llm_output,
            "generated_caption": cap_to_gpt
        }
        with open(outpath, "a") as f:
            f.write(json.dumps(current_output)+"\n")

        print(llm_output)
        
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="objects extracting")
    parser.add_argument("-ip", "--caption_path", type=str, required=True)
    parser.add_argument("-op", "--output_file_path", type=str, required=True)
    args = parser.parse_args()
    main(args)

